{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Counting Tales\n",
    "\n",
    "Towards an Algorithmic Analysis of Folk Narratives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Counting Texts\n",
    "\n",
    "In the code below, we use `os.walk` which returns a tuple that contains the location and all its contents (both directories and files). The tuple in this case looks like this:\n",
    "\n",
    "    ('./texts', [], ['anc-088.txt', 'anc-089.txt', 'anc-090.txt', 'anc-091.txt', 'bro-001.txt', 'bro-002.txt', 'bro-003.txt', 'bro-004.txt', 'lau-013.txt', 'lau-014.txt', 'loh-157.txt', 'loh-158.txt', 'loh-159.txt', 'loh-160.txt', 'loh-161.txt', 'loh-162.txt', 'loh-162b.txt', 'loh-163.txt', 'loh-164.txt', 'loh-165.txt', 'uls-001.txt', 'uls-002.txt', 'uls-003.txt'])\n",
    "\n",
    "Here, the path is the one we provided, `./texts` and it contains no directories, only these files. The list of files is in the third position of the tuple -- the number 2 when counting from zero -- and we get to it with `.next()`. Our focus is only on the **len**gth of that list: **23**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "fileCount = len(os.walk('./texts').next()[2])\n",
    "\n",
    "print(fileCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For the record, here are our texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anc-088.txt', 'anc-089.txt', 'anc-090.txt', 'anc-091.txt', 'bro-001.txt', 'bro-002.txt', 'bro-003.txt', 'bro-004.txt', 'lau-013.txt', 'lau-014.txt', 'loh-157.txt', 'loh-158.txt', 'loh-159.txt', 'loh-160.txt', 'loh-161.txt', 'loh-162.txt', 'loh-162b.txt', 'loh-163.txt', 'loh-164.txt', 'loh-165.txt', 'uls-001.txt', 'uls-002.txt', 'uls-003.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.walk('./texts').next()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's get some basic information about these texts: how long they are and how many unique words occur in each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./texts/anc-088.txt\t333\t148\n",
      "./texts/anc-089.txt\t153\t86\n",
      "./texts/anc-090.txt\t138\t75\n",
      "./texts/anc-091.txt\t174\t111\n",
      "./texts/bro-001.txt\t117\t74\n",
      "./texts/bro-002.txt\t122\t79\n",
      "./texts/bro-003.txt\t136\t90\n",
      "./texts/bro-004.txt\t67\t50\n",
      "./texts/lau-013.txt\t384\t185\n",
      "./texts/lau-014.txt\t676\t218\n",
      "./texts/loh-157.txt\t367\t180\n",
      "./texts/loh-158.txt\t193\t111\n",
      "./texts/loh-159.txt\t279\t149\n",
      "./texts/loh-160.txt\t760\t306\n",
      "./texts/loh-161.txt\t295\t141\n",
      "./texts/loh-162.txt\t331\t154\n",
      "./texts/loh-162b.txt\t194\t114\n",
      "./texts/loh-163.txt\t209\t120\n",
      "./texts/loh-164.txt\t1024\t339\n",
      "./texts/loh-165.txt\t904\t308\n",
      "./texts/uls-001.txt\t112\t68\n",
      "./texts/uls-002.txt\t188\t102\n",
      "./texts/uls-003.txt\t234\t121\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "files = {}\n",
    "for fpath in glob.glob(\"./texts/*.txt\"):\n",
    "    with open(fpath) as f:\n",
    "         fixed_text = re.sub(\"[^a-zA-Z'-]\",\" \",f.read())\n",
    "    files[fpath] = (len(fixed_text.split()),len(set(fixed_text.split())))\n",
    "\n",
    "for fname in sorted(files):\n",
    "    print fname + '\\t' + str(files[fname][0]) + '\\t' + str(files[fname][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "  <th>TEXT</th>\n",
    "  <th>Length</th>\n",
    "  <th>Unique</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "  <td>anc-088</td>\n",
    "  <td>333</td>\n",
    "  <td>148</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>anc-089</td>\n",
    "  <td>153</td>\n",
    "  <td>86</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>anc-090</td>\n",
    "  <td>138</td>\n",
    "  <td>75</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>anc-091</td>\n",
    "  <td>174</td>\n",
    "  <td>111</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>bro-001</td>\n",
    "  <td>117</td>\n",
    "  <td>74</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>bro-002</td>\n",
    "  <td>122</td>\n",
    "  <td>79</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>bro-003</td>\n",
    "  <td>136</td>\n",
    "  <td>90</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>bro-004</td>\n",
    "  <td>67</td>\n",
    "  <td>50</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>lau-013</td>\n",
    "  <td>384</td>\n",
    "  <td>185</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>lau-014</td>\n",
    "  <td>676</td>\n",
    "  <td>218</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-157</td>\n",
    "  <td>367</td>\n",
    "  <td>180</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-158</td>\n",
    "  <td>193</td>\n",
    "  <td>111</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-159</td>\n",
    "  <td>279</td>\n",
    "  <td>149</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-160</td>\n",
    "  <td>760</td>\n",
    "  <td>306</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-161</td>\n",
    "  <td>295</td>\n",
    "  <td>141</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-162</td>\n",
    "  <td>331</td>\n",
    "  <td>154</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-162b</td>\n",
    "  <td>194</td>\n",
    "  <td>114</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-163</td>\n",
    "  <td>209</td>\n",
    "  <td>120</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-164</td>\n",
    "  <td>1024</td>\n",
    "  <td>339</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>loh-165</td>\n",
    "  <td>904</td>\n",
    "  <td>308</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>uls-001</td>\n",
    "  <td>112</td>\n",
    "  <td>68</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>uls-002</td>\n",
    "  <td>188</td>\n",
    "  <td>102</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>uls-003</td>\n",
    "  <td>234</td>\n",
    "  <td>121</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Sample Text\n",
    "\n",
    "Let's take a look at the first text on that list, **Ancelet 89**, which is 153 words long with 86 unique words:\n",
    "\n",
    "> I went to meet an old man in Marrero, and he told me a story. He went to look for a treasure with some other men. And there was a controller who had brought a Bible to control the spirits. And when they arrived at the site, they saw a big horse coming through the woods with a man riding it, and when he dismounted, it was no longer a man on the horse. It was a dog. And he said the dog came and rubbed itself against his legs. He said it was growling. He said he knew the dog was touching him, but he didn't feel anything. It was like there was just a wind. And he said they all took off running. He lost his hat and his glasses and he tore all his clothes. And even the controller ran off and he never saw his Bible again after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Words, Words, Words\n",
    "\n",
    "If take a look at all the words that occur more than once in the text, we arrive at the following enumeration:\n",
    "\n",
    "* **double digits**: he (12), and (11)\n",
    "* **a lot**: a (9), was (7), the (7), it (5), his (5), said (4)\n",
    "* **three times**: to (3), they (3), man (3), dog (3)\n",
    "* **twice**: with, when, went, there, saw, off, horse, controller, bible, all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Words that Count\n",
    "\n",
    "With perhaps the exception of **he/his** as indicative of gender roles and **said** as a possible polysyndetic chaining syntax and/or traditionalizing/authorizing claim, many of the most frequently-used words do not contribute to the meaning of the text. *Many of these words are considered **functional** words, in contrast with **lexical** words, and are often dropped from algorithmic analyses that focus on content matters.*\n",
    "\n",
    "If we focus on nouns and verbs we can reduce the text to the following:\n",
    "\n",
    "    man (3), dog (3), went (2), saw (2), horse (2), controller (2), bible (2)\n",
    "\n",
    "Another way to represent this text is as a row with the text's name at the beginning, and then each item that follows represents one of the words (in the order above) and how many times it occurs:\n",
    "\n",
    "    ANC-089, 3, 3, 2, 2, 2, 2, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing Word Counts\n",
    "\n",
    "What happens when we compare several texts along these seven dimensions: man, dog, went, saw, horse, controller, bible? Here's our current text again:\n",
    "\n",
    "    ANC-089, 3, 3, 2, 2, 2, 2, 2\n",
    "\n",
    " And here are some others from the collection:\n",
    "\n",
    "    ANC-088, 3, 0, 2, 0, 0, 3, 0 #Words in common: man, went, controller\n",
    "    LAU-013, 3, 0, 3, 0, 0, 0, 0 #Words in common: man, went"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adding Words/Dimensions\n",
    "\n",
    "If we add two dimensions, *bull* and *shovel*, both of which appear in the two additional texts, we see the following:\n",
    "\n",
    "    ANC-089, 3, 3, 2, 2, 2, 2, 2, 0, 0\n",
    "    ANC-088, 3, 0, 2, 0, 0, 3, 0, 3, 1\n",
    "    LAU-013, 3, 0, 3, 0, 0, 0, 0, 3, 2\n",
    "\n",
    "The latter two texts would appear to have a great deal in common. For the record, both of these texts treat the matter of getting treasure out of the ground with a religious figure. However, Laudun 13 has a relative to the narrator preaching, not an external figure, as in the two Ancelet texts, called a \"spirit controller.\" (We will have to deal with the problem of synonyms later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "Fernando Pérez, Brian E. Granger, IPython: A System for Interactive Scientific Computing, Computing in Science and Engineering, vol. 9, no. 3, pp. 21-29, May/June 2007, doi:10.1109/MCSE.2007.53. URL: http://ipython.org"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
